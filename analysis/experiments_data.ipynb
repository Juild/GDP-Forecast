{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") # append the directory above where the databese is.\n",
    "from utils import config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import xgboost as xgb\n",
    "from numba import jit\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "%load_ext line_profiler\n",
    "### disable scientific notation in pandas\n",
    "pd.set_option('display.float_format', '{:.2f}'.format) ### display up to 2 decimal pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_hyperparams = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 10,\n",
    "    'learning_rate': 0.1,\n",
    "    'loss': 'ls'\n",
    "}\n",
    "gbm_model = models.GDPGrowthPredictor(**gbm_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_model.training_dataset = config.DATABASE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_model.training_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_others_GDP(df_origin):\n",
    "    df = df_origin[config.GDP_GROWTH].copy()\n",
    "    n_countries = df.index.get_level_values(level=\"CountryCode\").nunique()\n",
    "    countries = df.index.get_level_values(level=\"CountryCode\").unique()\n",
    "    n_years = df.index.get_level_values(level=\"Year\").nunique()\n",
    "    n_rows = df.shape[0]\n",
    "    dfs = []\n",
    "    m = 0\n",
    "    while(m + n_years <= n_rows):\n",
    "        df_slice = df.iloc[m:m + n_years]\n",
    "        dfs.append(df_slice)\n",
    "        m += n_years\n",
    "    # actually dfs elements are series, we will keep working with them because I've seen it is lighter to work with\n",
    "    # series than with dataframes\n",
    "    for i in range(len(dfs)):\n",
    "        df_aux = dfs[i]\n",
    "        df_copies = []\n",
    "        for _ in range(n_countries):\n",
    "            df_copies.append(dfs[i].copy())\n",
    "        dfs[i] = pd.concat(df_copies)\n",
    "    i = 0\n",
    "    for series in dfs:\n",
    "        series.rename(f\"{config.GDP_GROWTH}_Country.{countries[i]}\", inplace=True)\n",
    "        i += 1\n",
    "    dfs_frames = [series.to_frame().reset_index(drop=True) for series in dfs]\n",
    "    dfs_joined = dfs_frames[0].join(dfs_frames[1:], how=\"left\")\n",
    "    dfs_joined.set_index(df.index, inplace=True)\n",
    "    df_final = df_origin.join(dfs_joined)\n",
    "    return df_final # now we don't want the original gdp as it's repeated in the column with key f\"config.GDP_{country}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_and_pivote(df):\n",
    "    countries_gdp = df[df[\"IndicatorCode\"] == config.GDP_GROWTH][\"CountryCode\"].to_list() #countries with gdp\n",
    "    countries = df[\"CountryCode\"].unique()\n",
    "    countries_no_gdp = list(set(sorted(countries)) - set(sorted(countries_gdp))) # set difference =  countries with no gdp\n",
    "\n",
    "    return df.pivot(index=[\"CountryCode\",\"Year\"], columns=\"IndicatorCode\", values=\"Value\").drop(countries_no_gdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lags_f(df, lags=0):\n",
    "    countries = df.index.get_level_values(level=\"CountryCode\").unique()\n",
    "    years = df.index.get_level_values(level=\"Year\").unique()[lags:]\n",
    "    df_chunks = []\n",
    "    \n",
    "    for country in countries:\n",
    "        df_chunks_country = []\n",
    "        for year in years:\n",
    "            df_aux = df.loc[country].loc[range(year, year - lags - 1, -1)]\n",
    "            #print(df_aux)\n",
    "            rows = []\n",
    "            for y in df_aux.index.get_level_values(level=\"Year\"):\n",
    "                rows.append(df_aux.loc[y].to_frame().T)\n",
    "            lag = 0\n",
    "            for df_row in rows:\n",
    "                df_row.rename(columns={column: f\"{column}.LAG:{lag}\" for column in df_row.columns}, inplace=True)\n",
    "                df_row.reset_index(drop=True, inplace=True)\n",
    "                lag += 1\n",
    "            rows_concat = pd.concat(rows, axis=1)\n",
    "            rows_concat[\"CountryCode\"] = country\n",
    "            rows_concat[\"Year.range\"] = f\"{year} - {year - lags}\"\n",
    "            rows_concat.set_index([\"CountryCode\", \"Year.range\"], inplace=True)\n",
    "            df_chunks_country.append(rows_concat)\n",
    "        df_chunks.append(pd.concat(df_chunks_country, axis=0))\n",
    "        print(country)\n",
    "    return pd.concat(df_chunks, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqlite3.connect(config.DATABASE_PATH) as connection:\n",
    "    df = pd.read_sql(\"SELECT * FROM CountryIndicators\", connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_cleaned = clean_and_pivote(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_features = add_others_GDP(df_cleaned) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_year_ranges = lags_f(df_features, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_features = df_year_ranges.drop(index=\"2010 - 2007\", level=\"Year.range\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = df_cleaned.pop(config.GDP_GROWTH)\n",
    "df_target = df_target.drop(index=range(1960,1971), level=\"Year\")\n",
    "print(f\"{df_features.index} \\t {df_target.index}\")\n",
    "df_target.to_csv(\"target.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_year_ranges.join(df_target, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = df_pivoted.pop(config.GDP)\n",
    "df_features.drop(index=2010, level=\"Year\", inplace=True)\n",
    "df_target.drop(index=1960, level=\"Year\", inplace=True)\n",
    "# up until here we have the basic features selected. Now we want to add more features, like the GDP of each country\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_features\n",
    "y = df_target.to_frame()\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "imp_mode = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")\n",
    "# genereate imputed dataframes\n",
    "X_imp = imp_mode.fit_transform(X) \n",
    "y_imp = imp_mode.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imp, y_imp, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor(max_depth=7, learning_rate=0.01, subsample=0.8, n_estimators=1000, base_score=y_train.mean())\n",
    "# model.fit(X_train, y_train, eval_set=[(X_test,y_test)], eval_metric=\"rmse\", verbose=1000, early_stopping_rounds=20)\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test, output_margin=True)\n",
    "print(\"Model absolute error =\", mean_absolute_error(y_test, pred))\n",
    "print(\"Model squared error =\", mean_squared_error(y_test, pred))\n",
    "print(\"R2 =\", r2_score(y_test, pred))"
   ]
  }
 ]
}